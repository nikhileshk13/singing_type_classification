# Singing Type Classification
<br>
In this project I have created a singing type classification system. I have used vggish model to get embedding for the input data and then created a custom artificial neural network model to get the final classification output. <br><br>
Here is the model summary for the custom artificial neural network mode -: <br>
<p align="left">
  <img src="https://github.com/nikhileshk13/singing_type_classification/blob/main/images/ann_model_summary.png"/ width=600>
</p>
For this task I have used the Vocalset Dataset. The dataset contains audio clips from multiple different singers categorised by the vocal type, vowels and singers. <br><br>
<a href='https://zenodo.org/records/1193957'>Dataset Link<a/><br><br>
These are the following 17 different vocal types that the model can identify -: <br>
<ul>
<li>Belt
<li>Breathy
<li>Fast Forte
<li>Fast Piano
<li>Forte
<li>Inhaled
<li>Lip Trill
<li>Messa
<li>Pianissimo
<li>Slow Forte
<li>Slow Piano
<li>Spoken
<li>Straight
<li>Trill
<li>Trillo
<li>Vibrato
<li>Vocal Fry</li>