# Singing Type Classification
<br>
In this project I have created a singing type classification system. I have used vggish model to get embedding for the input data and then created a custom artificial neural network model to get the final classification output. <br><br>
Here is the model summary for the custom artificial neural network mode -: <br>
<p align="left">
  <img src="https://github.com/nikhileshk13/singing_type_classification/blob/main/images/ann_model_summary.png"/ width=600>
</p>
For this task I have used the Vocalset Dataset. The dataset contains audio clips from multiple different singers categorised by the vocal type, vowels and singers. <br><br>
<a href='https://zenodo.org/records/1193957'>Dataset Link<a/><br><br>
These are the following 17 different vocal types that the model can identify -: <br>
* Belt <br>
* Breathy <br>
* Fast Forte <br>
* Fast Piano <br>
* Forte <br>
* Inhaled <br>
* Lip Trill <br>
* Messa <br>
* Pianissimo <br>
* Slow Forte <br>
* Slow Piano <br>
* Spoken <br>
* Straight <br>
* Trill <br>
* Trillo <br>
* Vibrato <br>
* Vocal Fry <br>

<ul>
<li>1</li>
<li>1</li>
<li>1</li>
</ul>
