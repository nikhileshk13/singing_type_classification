# Singing Type Classification
<br>
In this project I have created a singing type classification system. I have used vggish model to get embedding for the input data and then created a custom artificial neural network model to get the final classification output. <br><br>
Here is the model summary for the custom artificial neural network mode -: <br>
<p align="left">
  <img src="https://github.com/nikhileshk13/singing_type_classification/blob/main/images/ann_model_summary.png"/ width=600>
</p>
For this task I have used the Vocalset Dataset. The dataset contains audio clips from multiple different singers categorised by the vocal type, vowels and singers. <br><br>
<a href='https://zenodo.org/records/1193957'>Dataset Link<a/><br><br>
These are the following 17 different vocal types that the model can identify -: <br>
<ul>
<li>Belt<\li>
<li>Breathy<\li>
<li>Fast Forte<\li>
<li>Fast Piano<\li>
<li>Forte<\li>
<li>Inhaled<\li>
<li>Lip Trill<\li>
<li>Messa<\li>
<li>Pianissimo<\li>
<li>Slow Forte<\li>
<li>Slow Piano<\li>
<li>Spoken<\li>
<li>Straight<\li>
<li>Trill<\li>
<li>Trillo<\li>
<li>Vibrato<\li>
<li>Vocal Fry<\li>
<\ul>